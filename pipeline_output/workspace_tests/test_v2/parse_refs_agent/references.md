# Extracted References


## Paper (6)

- [Attention Is All You Need](https://papers.nips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html)
- [BERT: Pre-training of Deep Bidirectional Transformers](https://aclanthology.org/N19-1423)
- [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://openreview.net/forum?id=YicbFdNTTy)
- [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper.pdf)
- [Array programming with NumPy](https://doi.org/10.1038/s41586-020-2649-2)
- [Deep Learning](https://doi.org/10.1038/nature14539)

## Website (10)

- [https://papers.nips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html](https://papers.nips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html)
  - Attention Is All You Need
- [https://aclanthology.org/N19-1423](https://aclanthology.org/N19-1423)
  - BERT: Pre-training of Deep Bidirectional Transformers
- [https://openreview.net/forum?id=YicbFdNTTy](https://openreview.net/forum?id=YicbFdNTTy)
  - An Image is Worth 16x16 Words
- [https://jalammar.github.io/illustrated-transformer/](https://jalammar.github.io/illustrated-transformer/)
  - The Illustrated Transformer
- [http://nlp.seas.harvard.edu/2018/04/03/attention.html](http://nlp.seas.harvard.edu/2018/04/03/attention.html)
  - The Annotated Transformer
- [https://towardsdatascience.com/transformers-from-nlp-to-computer-vision-4f237386610c/](https://towardsdatascience.com/transformers-from-nlp-to-computer-vision-4f237386610c/)
  - Transformers from NLP to Computer Vision
- [https://huggingface.co/docs/transformers](https://huggingface.co/docs/transformers)
  - Transformers Documentation
- [https://pytorch.org/tutorials/beginner/transformer_tutorial.html](https://pytorch.org/tutorials/beginner/transformer_tutorial.html)
  - PyTorch Transformer Tutorial
- [https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md](https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md)
  - Llama 3 Model Card
- [https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model))
  - Transformer (machine learning model)

## Doi (4)

- [10.18653/v1/N19-1423](https://doi.org/10.18653/v1/N19-1423)
  - BERT: Pre-training of Deep Bidirectional Transformers
- [10.1109/ICCV48922.2021.00986](https://doi.org/10.1109/ICCV48922.2021.00986)
  - Swin Transformer: Hierarchical Vision Transformer using Shifted Windows
- [10.1038/s41586-020-2649-2](https://doi.org/10.1038/s41586-020-2649-2)
  - Array programming with NumPy
- [10.1038/nature14539](https://doi.org/10.1038/nature14539)
  - Deep Learning

## Pdf (1)

- [https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper.pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper.pdf)
  - Swin Transformer: Hierarchical Vision Transformer using Shifted Windows

## Arxiv (3)

- [2303.08774](https://arxiv.org/abs/2303.08774)
  - GPT-4 Technical Report
- [2407.21783](https://arxiv.org/abs/2407.21783)
  - The Llama 3 Herd of Models
- [2302.13971](https://arxiv.org/abs/2302.13971)
  - LLaMA: Open and Efficient Foundation Language Models

## Github (3)

- [pytorch/pytorch](https://github.com/pytorch/pytorch)
  - PyTorch
- [huggingface/transformers](https://github.com/huggingface/transformers)
  - Hugging Face Transformers
- [microsoft/Swin-Transformer](https://github.com/microsoft/Swin-Transformer)
  - Swin-Transformer

## Youtube (3)

- [kCc8FmEb1nY](https://www.youtube.com/watch?v=kCc8FmEb1nY)
  - Let's build GPT: from scratch, in code, spelled out
- [iDulhoQ2pro](https://www.youtube.com/watch?v=iDulhoQ2pro)
  - Attention is All You Need - Paper Explained
- [wjZofJX0v4M](https://www.youtube.com/watch?v=wjZofJX0v4M)
  - Transformers, the tech behind LLMs