[
  {
    "title": "",
    "doi": "10.48550/arXiv.2303.08774",
    "pdf_url": null,
    "arxiv_id": "2303.08774"
  },
  {
    "title": "",
    "doi": "10.48550/arXiv.2407.21783",
    "pdf_url": null,
    "arxiv_id": "2407.21783"
  },
  {
    "title": "",
    "doi": "10.48550/arXiv.2302.13971",
    "pdf_url": null,
    "arxiv_id": "2302.13971"
  },
  {
    "title": "",
    "doi": "10.1038/s41586-020-2649-2",
    "pdf_url": null,
    "arxiv_id": null
  },
  {
    "title": "",
    "doi": "10.1038/nature14539",
    "pdf_url": null,
    "arxiv_id": null
  },
  {
    "title": "",
    "doi": "10.18653/v1/N19-1423",
    "pdf_url": null,
    "arxiv_id": null
  },
  {
    "title": "",
    "doi": "10.1109/ICCV48922.2021.00986",
    "pdf_url": null,
    "arxiv_id": null
  },
  {
    "title": "An Image is Worth 16x16 Words",
    "doi": null,
    "pdf_url": null,
    "arxiv_id": null
  },
  {
    "title": "Array programming with NumPy",
    "doi": null,
    "pdf_url": null,
    "arxiv_id": null
  },
  {
    "title": "Deep Learning",
    "doi": null,
    "pdf_url": null,
    "arxiv_id": null
  },
  {
    "title": "Attention Is All You Need",
    "doi": null,
    "pdf_url": null,
    "arxiv_id": null
  },
  {
    "title": "BERT: Pre-training of Deep Bidirectional Transformers",
    "doi": null,
    "pdf_url": null,
    "arxiv_id": null
  },
  {
    "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
    "doi": null,
    "pdf_url": null,
    "arxiv_id": null
  },
  {
    "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows",
    "doi": null,
    "pdf_url": null,
    "arxiv_id": null
  },
  {
    "title": "GPT-4 Technical Report",
    "doi": null,
    "pdf_url": null,
    "arxiv_id": null
  },
  {
    "title": "The Llama 3 Herd of Models",
    "doi": null,
    "pdf_url": null,
    "arxiv_id": null
  },
  {
    "title": "LLaMA: Open and Efficient Foundation Language Models",
    "doi": null,
    "pdf_url": null,
    "arxiv_id": null
  }
]